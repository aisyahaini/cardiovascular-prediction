import streamlit as st
import numpy as np
import pandas as pd
import onnxruntime as ort
import json
import matplotlib.pyplot as plt

# =========================
# CONFIG
# =========================
st.set_page_config(page_title="CVD Prediction (ONNX)", layout="wide")

# =========================
# LOAD MODEL
# =========================
@st.cache_resource
def load_model():
    sess = ort.InferenceSession(
        "adaboost_model.onnx",
        providers=["CPUExecutionProvider"]
    )

    with open("feature_names.json") as f:
        feature_names = json.load(f)

    input_name = sess.get_inputs()[0].name
    output_names = [o.name for o in sess.get_outputs()]

    return sess, feature_names, input_name, output_names


session, FEATURE_NAMES, INPUT_NAME, OUTPUT_NAMES = load_model()

# =========================
# SAFE PROBA EXTRACTOR
# =========================
def extract_probability(raw):
    """
    Universal ONNX probability extractor
    Works for:
    - numpy array
    - list
    - dict
    """
    # Case 1: dict (sklearn AdaBoost often)
    if isinstance(raw, dict):
        return float(raw.get(1, list(raw.values())[-1]))

    # Case 2: list of dict
    if isinstance(raw, list) and isinstance(raw[0], dict):
        return float(raw[0].get(1, list(raw[0].values())[-1]))

    # Case 3: numpy array
    raw = np.asarray(raw)

    if raw.ndim == 2:
        return float(raw[0, 1])

    if raw.ndim == 1:
        return float(raw[0])

    raise ValueError("Unknown ONNX probability output format")

# =========================
# UI
# =========================
st.title("ğŸ«€ Prediksi Manual Penyakit Cardiovascular (Single Input)")

with st.form("input_form"):
    age = st.number_input("Age", 1, 120, 50)
    sex = st.selectbox("Sex", ["Female", "Male"])
    sex = 1 if sex == "Male" else 0
    cp = st.selectbox("Chest Pain Type", [0, 1, 2, 3])
    trestbps = st.number_input("Resting BP", 80, 250, 120)
    chol = st.number_input("Cholesterol", 100, 600, 230)
    fbs = st.selectbox("Fasting Blood Sugar > 120", [0, 1])
    restecg = st.selectbox("Rest ECG", [0, 1, 2])
    thalach = st.number_input("Max Heart Rate", 60, 220, 150)
    exang = st.selectbox("Exercise Angina", [0, 1])
    oldpeak = st.number_input("ST Depression", 0.0, 10.0, 1.0)
    slope = st.selectbox("Slope", [0, 1, 2])
    ca = st.selectbox("CA", [0, 1, 2, 3])
    thal = st.selectbox("Thal", [0, 1, 2, 3])

    submit = st.form_submit_button("Predict")

# =========================
# PREDICTION
# =========================
if submit:
    input_data = pd.DataFrame([{
        "age": age,
        "sex": sex,
        "chest_pain_type": cp,
        "resting_blood_pressure": trestbps,
        "cholesterol": chol,
        "fasting_blood_sugar": fbs,
        "Restecg": restecg,
        "max_heart_rate_achieved": thalach,
        "exercise_induced_angina": exang,
        "st_depression": oldpeak,
        "st_slope_type": slope,
        "num_major_vessels": ca,
        "thalassemia_type": thal
    }])

    for col in FEATURE_NAMES:
        if col not in input_data:
            input_data[col] = 0

    X = (
        input_data[FEATURE_NAMES]
        .astype(np.float32)
        .values
    )

    outputs = session.run(
        OUTPUT_NAMES,
        {INPUT_NAME: X}
    )

    # LABEL
    pred = int(outputs[0][0])

    # PROBABILITY (SAFE)
    prob = extract_probability(outputs[1])

    # =========================
    # OUTPUT
    # =========================
    st.subheader("ğŸ“Š Result")
    st.metric("CVD Probability", f"{prob:.2f}")

    st.success("CVD Detected" if pred == 1 else "No CVD Detected")

    # =========================
    # SIMPLE FEATURE IMPACT
    # =========================
    st.subheader("ğŸ§  Feature Impact")

    impacts = []
    base_prob = prob

    for i, name in enumerate(FEATURE_NAMES):
        X_temp = X.copy()
        X_temp[0, i] = 0

        out = session.run(
            OUTPUT_NAMES,
            {INPUT_NAME: X_temp}
        )

        new_prob = extract_probability(out[1])
        impacts.append((name, base_prob - new_prob))

    df_imp = pd.DataFrame(impacts, columns=["Feature", "Impact"]) \
        .sort_values("Impact", ascending=False)

    st.dataframe(df_imp.head(8))

    fig, ax = plt.subplots()
    df_imp.head(8).plot.barh(x="Feature", y="Impact", ax=ax, legend=False)
    ax.invert_yaxis()
    st.pyplot(fig)

# =========================
# INTERPRETASI HASIL (LIME-STYLE NARRATIVE)
# =========================
st.subheader("ğŸ“ Interpretasi Hasil Prediksi")

# Confidence level
if prob >= 0.75:
    confidence = "tinggi"
elif prob >= 0.5:
    confidence = "sedang"
else:
    confidence = "rendah"

# Pisahkan fitur berdasarkan kontribusi
positive_features = df_imp[df_imp["Impact"] > 0].head(5).values.tolist()
negative_features = df_imp[df_imp["Impact"] < 0].head(5).values.tolist()

st.markdown(f"""
Model **AdaBoost** mampu memprediksi risiko penyakit kardiovaskular (**CVD**)
dengan tingkat keyakinan **{confidence}**
(probabilitas **{prob:.2f}**).

Berdasarkan **LIME (Local Interpretable Model-agnostic Explanation)**,
prediksi pada **satu pasien** ini terutama dipengaruhi oleh perubahan
nilai fitur di sekitar instance yang dianalisis.
""")

# Fitur yang meningkatkan risiko
if positive_features:
    st.markdown("ğŸ”º **Fitur yang meningkatkan risiko:**")
    for f, w in positive_features:
        st.markdown(f"- **{f} > 0.00** (kontribusi: `{w:.3f}`)")

# Fitur yang menurunkan risiko
if negative_features:
    st.markdown("ğŸ”» **Fitur yang menurunkan risiko:**")
    for f, w in negative_features:
        st.markdown(f"- **{f} â‰¤ 0.00** (kontribusi: `{abs(w):.3f}`)")

# =========================
# KESIMPULAN ILMIAH
# =========================
st.subheader("ğŸ“Œ Kesimpulan Ilmiah")

st.markdown("""
- **LIME lebih unggul untuk analisis individual**, karena mampu menjelaskan
  keputusan model secara spesifik pada satu pasien.
- **SHAP tetap memiliki keunggulan**, terutama untuk analisis global,
  karena konsisten secara teoritis dan stabil terhadap seluruh dataset.
- Oleh karena itu, pada **single input**, pendekatan berbasis **LIME**
  menjadi metode utama dalam interpretasi,
  sementara **SHAP berfungsi sebagai pendukung interpretasi global model**.
""")


dari code diatas berikan tambahan analisis seperti shap tapi ga pake lib dari shap langsung, dan berikan analisis untuk hasil shap nya diletakkan sebelum feature impact atau lime. dan berikan semua code perbaikan untuk single input nya 


